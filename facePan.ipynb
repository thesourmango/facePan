{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Example with image\n",
    "Swap test1.jpg to eg test4.jpg to see it detect multiple faces\n",
    "\n",
    "\n",
    "Note:\n",
    "Haar is better at detecting faces but almost 10x slower.\n",
    "haar_face_cascade = cv2.CascadeClassifier('data/haarcascade_frontalface_alt.xml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Faces found:  7\n"
     ]
    }
   ],
   "source": [
    "#import required libraries \n",
    "import cv2 #import OpenCV library\n",
    "#load cascade classifier training file for lbpcascade\n",
    "lbp_face_cascade = cv2.CascadeClassifier('data/lbpcascade_frontalface.xml')\n",
    "\n",
    "#load test image\n",
    "testImg = cv2.imread('data/test4.jpg')\n",
    "# convert the test image to gray image as opencv face detector expects gray images\n",
    "gray_img = cv2.cvtColor(testImg, cv2.COLOR_BGR2GRAY)\n",
    "#detect multiscale faces (some images may be closer to camera than others) images\n",
    "faces = lbp_face_cascade.detectMultiScale(gray_img, scaleFactor=1.2, minNeighbors=5); \n",
    "# print the number of faces found\n",
    "print('Faces found: ', len(faces))\n",
    "\n",
    "# go over list of faces and draw them as rectangles on img\n",
    "for (x, y, w, h) in faces:\n",
    "    cv2.rectangle(testImg, (x, y), (x+w, y+h), (0, 255, 0), 2)\n",
    "\n",
    "# convert gray image to RGB and show image\n",
    "cv2.imshow('test_image', testImg) # show result img\n",
    "\n",
    "# PRESS ESC TO EXIT\n",
    "cv2.waitKey(0) == 27\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Example with video\n",
    "Careful with frame size!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import required libraries \n",
    "import cv2 #import OpenCV library\n",
    "#importing time library\n",
    "import time \n",
    "# matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "#load cascade classifier training file for lbpcascade\n",
    "lbp_face_cascade = cv2.CascadeClassifier('data/lbpcascade_frontalface.xml')\n",
    "# NOW USING HAAR BCAUSE OF ACCURACY BUT TBP IS WAAY FASTER\n",
    "haar_face_cascade = cv2.CascadeClassifier('data/haarcascade_frontalface_alt.xml')\n",
    "# cam is the videofeed from video0\n",
    "cam = cv2.VideoCapture(0)\n",
    "cam.set(cv2.CAP_PROP_FRAME_WIDTH, 320)\n",
    "cam.set(cv2.CAP_PROP_FRAME_HEIGHT, 180)\n",
    "# use uvcdynctrl -f to find out device frame formats\n",
    "cam.set(cv2.CAP_PROP_FPS, 15)\n",
    "    \n",
    "while True: # loop bcause video\n",
    "    (re, img) = cam.read() # Grab tuples from cam (True/False, Frame)\n",
    "    # convert the test image to gray image as opencv face detector expects gray images\n",
    "    gray_img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    # detect faces\n",
    "    faces = haar_face_cascade.detectMultiScale(gray_img, scaleFactor=1.1, minNeighbors=4); \n",
    "\n",
    "    # go over list of faces and draw them as rectangles on img\n",
    "    for (x, y, w, h) in faces:\n",
    "        cv2.rectangle(img, (x, y), (x+w, y+h), (0, 255, 0), 2)\n",
    "\n",
    "    # Show result\n",
    "    cv2.imshow('test', img) # show result img\n",
    "    time.sleep(0.2) #this works as a limiter\n",
    "\n",
    "    \n",
    "    # PRESS ESC TO EXIT\n",
    "    if cv2.waitKey(1) == 27:\n",
    "        break\n",
    "cam.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Trial with crop\n",
    "Attempting to follow the face in the frame, crashes when face nears edge bcause fram size < 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import required libraries \n",
    "import cv2 #import OpenCV library\n",
    "import time #importing time library\n",
    "#load cascade classifier training file for lbpcascade\n",
    "lbp_face_cascade = cv2.CascadeClassifier('data/lbpcascade_frontalface.xml')\n",
    "# cam is the videofeed from video0\n",
    "cam = cv2.VideoCapture(0)\n",
    "cam.set(cv2.CAP_PROP_FRAME_WIDTH, 320)\n",
    "cam.set(cv2.CAP_PROP_FRAME_HEIGHT, 180)\n",
    "cam.set(cv2.CAP_PROP_FPS, 15) # use uvcdynctrl -f to find out device frame formats\n",
    "    \n",
    "while True: # loop bcause video\n",
    "    (re, img) = cam.read() # Grab tuples from cam (True/False, Frame)\n",
    "    # convert the test image to gray image as opencv face detector expects gray images\n",
    "    gray_img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    # detect faces\n",
    "    faces = haar_face_cascade.detectMultiScale(gray_img, scaleFactor=1.1, minNeighbors=4); \n",
    "\n",
    "    # go over list of faces and draw them as rectangles on img\n",
    "    for (x, y, w, h) in faces:\n",
    "        cv2.rectangle(img, (x, y), (x+w, y+h), (0, 255, 0), 2)\n",
    "        crop_img = img[y-45:y+45+h, x-80:x+80+w]\n",
    "        cv2.imshow(\"cropped\", crop_img)\n",
    "    #cropping\n",
    "    # Show result\n",
    "    #cv2.imshow('test', img) # show result img\n",
    "    #time.sleep(1) #this works as a limiter\n",
    "\n",
    "    \n",
    "    # PRESS ESC TO EXIT\n",
    "    if cv2.waitKey(1) == 27:\n",
    "        break\n",
    "cam.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fixed crash on nearing edge by hardcoding limits to y and x\n",
    "Working script, lpb cascades are much faster than haar, but bad in this application (big FOV, small face)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import required libraries \n",
    "import cv2 #import OpenCV library\n",
    "import time #importing time library\n",
    "#load cascade classifier training file for lbpcascade\n",
    "lbp_face_cascade = cv2.CascadeClassifier('data/lbpcascade_frontalface.xml')\n",
    "\n",
    "cam = cv2.VideoCapture(0) # cam is the videofeed from video0\n",
    "cam.set(cv2.CAP_PROP_FRAME_WIDTH, 320)\n",
    "cam.set(cv2.CAP_PROP_FRAME_HEIGHT, 180)\n",
    "cam.set(cv2.CAP_PROP_FPS, 15) # use uvcdynctrl -f to find out device frame formats\n",
    "t1 = time.time() # DEBUG: start timer for monitoring speed\n",
    "\n",
    "# Function to crop video\n",
    "def cropvideo(frame,faces):\n",
    "    for (x,y,w,h) in faces:\n",
    "        if y <=45: # dont crop when nearing top of frame\n",
    "            y = 45\n",
    "        if x<=80: # dont crop when nearing left of frame\n",
    "            x= 80\n",
    "        global crop_img\n",
    "        crop_img = frame[y-45:y+45+h, x-80:x+80+w] # crop video to 1/4 size\n",
    "        # TODO: Check multiple face detection\n",
    "    return crop_img\n",
    "\n",
    "# Function to Track Face\n",
    "def facetrack(frame):\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    faces = lbp_face_cascade.detectMultiScale(gray, 1.2, 5) # img,scaleFactor,minNeighbors\n",
    "    for (x,y,w,h) in faces: # iterate through all found faces\n",
    "        cv2.rectangle(frame,(x,y),(x+w,y+h),(0,255,0),2) # draw a rectangle\n",
    "    return faces\n",
    "\n",
    "def main():\n",
    "    # Program function\n",
    "    while True:\n",
    "        (ret, frame) = cam.read() # Grab tuples from cam (True/False, Frame)\n",
    "        faces = facetrack(frame)\n",
    "        crop_img = cropvideo(frame,faces)\n",
    "        cv2.imshow(\"cropped\", crop_img)\n",
    "        t5 = time.time() # DEBUG: check how long processing takes\n",
    "        #print(\"Frame displayed at \" + str(round(t5-t1, 3)) + \"s\")\n",
    "\n",
    "        # PRESS ESC TO EXIT\n",
    "        if cv2.waitKey(50) == 27:\n",
    "            break\n",
    "    cam.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "#For starting the .py script\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "#### Swapped to Haar cascades, crop img even at previous x,y even though no face detected.\n",
    "Working script with Haar, still pretty bad at detecting small faces in big fram (which is exactly the point :p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import required libraries \n",
    "import cv2 #import OpenCV library\n",
    "import time #importing time library\n",
    "#load cascade classifier training file for lbpcascade\n",
    "lbp_face_cascade = cv2.CascadeClassifier('data/lbpcascade_frontalface.xml')\n",
    "# NOW USING HAAR BCAUSE OF ACCURACY BUT TBP IS WAAY FASTER\n",
    "haar_face_cascade = cv2.CascadeClassifier('data/haarcascade_frontalface_alt.xml')\n",
    "\n",
    "cam = cv2.VideoCapture(0) # cam is the videofeed from video0\n",
    "cam.set(cv2.CAP_PROP_FRAME_WIDTH, 320)\n",
    "cam.set(cv2.CAP_PROP_FRAME_HEIGHT, 180)\n",
    "cam.set(cv2.CAP_PROP_FPS, 15) # use uvcdynctrl -f to find out device frame formats\n",
    "t1 = time.time() # DEBUG: start timer for monitoring speed\n",
    "\n",
    "\n",
    "def main():\n",
    "    w = cv2.CAP_PROP_FRAME_WIDTH\n",
    "    h = cv2.CAP_PROP_FRAME_HEIGHT\n",
    "    y = 45\n",
    "    x= 80\n",
    "    # Program function\n",
    "    while True:\n",
    "        (ret, frame) = cam.read() # Grab tuples from cam (True/False, Frame)\n",
    "        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "        faces = haar_face_cascade.detectMultiScale(gray, 1.2, 5, 0, (0, 0)) # img,scaleFactor,minNeighbors, flags, min_size\n",
    "\n",
    "        if (len(faces)):\n",
    "            for (x,y,w,h) in faces: # iterate through all found faces\n",
    "                cv2.rectangle(frame,(x,y),(x+w,y+h),(0,255,0),2) # draw a rectangle\n",
    "                if y <=45: # dont crop when nearing top of frame\n",
    "                    y = 45\n",
    "                if x<=80: # dont crop when nearing left of frame\n",
    "                    x= 80\n",
    "                crop_img = frame[y-45:y+45+h, x-80:x+80+w] # crop video to 1/4 size\n",
    "                cv2.imshow(\"cropped\", crop_img)\n",
    "        else:\n",
    "            crop_img = frame[y-45:y+45+h, x-80:x+80+w]\n",
    "            cv2.imshow(\"cropped\", crop_img)\n",
    "        t5 = time.time() # DEBUG: check how long processing takes\n",
    "        #print(\"Frame displayed at \" + str(round(t5-t1, 3)) + \"s\")\n",
    "\n",
    "        # PRESS ESC TO EXIT\n",
    "        if cv2.waitKey(50) == 27:\n",
    "            break\n",
    "    cam.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "#For starting the .py script\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Bigger input frame, better detection of small faces\n",
    "Tried increasing frame size for more reliable detection (also bigger edges around frame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import required libraries \n",
    "import cv2 #import OpenCV library\n",
    "import time #importing time library\n",
    "#load cascade classifier training file for lbpcascade\n",
    "lbp_face_cascade = cv2.CascadeClassifier('data/lbpcascade_frontalface.xml')\n",
    "# NOW USING HAAR BCAUSE OF ACCURACY BUT LBP IS WAAY FASTER\n",
    "haar_face_cascade = cv2.CascadeClassifier('data/haarcascade_frontalface_alt.xml')\n",
    "\n",
    "cam = cv2.VideoCapture(0) # cam is the videofeed from video0\n",
    "cam.set(cv2.CAP_PROP_FRAME_WIDTH, 960)\n",
    "cam.set(cv2.CAP_PROP_FRAME_HEIGHT, 480)\n",
    "cam.set(cv2.CAP_PROP_FPS, 15) # use uvcdynctrl -f to find out device frame formats\n",
    "t1 = time.time() # DEBUG: start timer for monitoring speed\n",
    "\n",
    "\n",
    "def main():\n",
    "    w = cv2.CAP_PROP_FRAME_WIDTH\n",
    "    h = cv2.CAP_PROP_FRAME_HEIGHT\n",
    "    y = 135\n",
    "    x= 200\n",
    "    # Program function\n",
    "    while True:\n",
    "        (ret, frame) = cam.read() # Grab tuples from cam (True/False, Frame)\n",
    "        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "        faces = haar_face_cascade.detectMultiScale(gray, 1.2, 5, 0, (0, 0)) # img,scaleFactor,minNeighbors, flags, min_size\n",
    "\n",
    "        if (len(faces)):\n",
    "            for (x,y,w,h) in faces: # iterate through all found faces\n",
    "                cv2.rectangle(frame,(x,y),(x+w,y+h),(0,255,0),2) # draw a rectangle\n",
    "                if y <=135: # dont crop when nearing top of frame\n",
    "                    y = 135\n",
    "                if x<=200: # dont crop when nearing left of frame\n",
    "                    x= 200\n",
    "                crop_img = frame[y-135:y+135+h, x-200:x+200+w] # crop video to 1/4 size\n",
    "                cv2.imshow(\"cropped\", crop_img)\n",
    "        else:\n",
    "            crop_img = frame[y-135:y+135+h, x-200:x+200+w]\n",
    "            cv2.imshow(\"cropped\", crop_img)\n",
    "        t5 = time.time() # DEBUG: check how long processing takes\n",
    "        #print(\"Frame displayed at \" + str(round(t5-t1, 3)) + \"s\")\n",
    "\n",
    "        # PRESS ESC TO EXIT\n",
    "        if cv2.waitKey(50) == 27:\n",
    "            break\n",
    "    cam.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "#For starting the .py script\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### How to output video? Testing cv2.videoWriter\n",
    "Testing cell for streaming to .avi file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "480 640 3\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "ret, frame = cap.read()\n",
    "h, w, c = frame.shape\n",
    "print(h, w, c)\n",
    "\n",
    "fourcc = cv2.VideoWriter_fourcc('L','M','P','2')\n",
    "out = cv2.VideoWriter('output.avi', fourcc, 30.0, (w, h))\n",
    "\n",
    "while(True):\n",
    "    ret, frame = cap.read()\n",
    "\n",
    "    out.write(frame)\n",
    "\n",
    "    frame = cv2.resize(frame, (0,0), fx=1, fy=1)\n",
    "    cv2.imshow(\"Frame\", frame)\n",
    "\n",
    "    ch = cv2.waitKey(1)\n",
    "    if ch & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "out.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Included output to .avi (this avi can be used in OBS as media input!)\n",
    "Latest script, includes outputting to .avi file in MPEG2 for reading to OBS\n",
    "NOT WORKING - crop_img not the same size as out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import required libraries \n",
    "import cv2 #import OpenCV library\n",
    "import time #importing time library\n",
    "#load cascade classifier training file for lbpcascade\n",
    "lbp_face_cascade = cv2.CascadeClassifier('data/lbpcascade_frontalface.xml')\n",
    "# NOW USING HAAR BCAUSE OF ACCURACY BUT LBP IS WAAY FASTER\n",
    "haar_face_cascade = cv2.CascadeClassifier('data/haarcascade_frontalface_alt.xml')\n",
    "\n",
    "cam = cv2.VideoCapture(0) # cam is the videofeed from video0\n",
    "cam.set(cv2.CAP_PROP_FRAME_WIDTH, 960)\n",
    "cam.set(cv2.CAP_PROP_FRAME_HEIGHT, 480)\n",
    "cam.set(cv2.CAP_PROP_FPS, 15) # use uvcdynctrl -f to find out device frame formats\n",
    "t1 = time.time() # DEBUG: start timer for monitoring speed\n",
    "\n",
    "def main():\n",
    "    w = cv2.CAP_PROP_FRAME_WIDTH\n",
    "    h = cv2.CAP_PROP_FRAME_HEIGHT\n",
    "    y = 135\n",
    "    x= 200\n",
    "    fourcc = cv2.VideoWriter_fourcc('L','M','P','2')\n",
    "    out = cv2.VideoWriter('output.avi', fourcc, 30.0, (w, h))\n",
    "    \n",
    "    # Program function\n",
    "    while True:\n",
    "        (ret, frame) = cam.read() # Grab tuples from cam (True/False, Frame)\n",
    "        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "        faces = haar_face_cascade.detectMultiScale(gray, 1.2, 5, 0, (0, 0)) # img,scaleFactor,minNeighbors, flags, min_size\n",
    "\n",
    "        if (len(faces)):\n",
    "            for (x,y,w,h) in faces: # iterate through all found faces\n",
    "                cv2.rectangle(frame,(x,y),(x+w,y+h),(0,255,0),2) # draw a rectangle\n",
    "                if y <=135: # dont crop when nearing top of frame\n",
    "                    y = 135\n",
    "                if x<=200: # dont crop when nearing left of frame\n",
    "                    x= 200\n",
    "                crop_img = frame[y-135:y+135+h, x-200:x+200+w] # crop video to 1/4 size\n",
    "                cv2.imshow(\"cropped\", crop_img) # DEBUG: show cropped frame\n",
    "                out.write(crop_img) # push frame to avi\n",
    "        else:\n",
    "            crop_img = frame[y-135:y+135+h, x-200:x+200+w]\n",
    "            cv2.imshow(\"cropped\", crop_img) # DEBUG: show cropped frame\n",
    "            out.write(crop_img) # push frame to avi\n",
    "        t5 = time.time() # DEBUG: check how long processing takes\n",
    "        #print(\"Frame displayed at \" + str(round(t5-t1, 3)) + \"s\")\n",
    "\n",
    "        # PRESS ESC TO EXIT\n",
    "        if cv2.waitKey(50) == 27:\n",
    "            break\n",
    "    cam.release()\n",
    "    out.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "#For starting the .py script\n",
    "if __name__ == '__main__':\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import required libraries \n",
    "import cv2 #import OpenCV library\n",
    "import time #importing time library\n",
    "#load cascade classifier training file for lbpcascade\n",
    "lbp_face_cascade = cv2.CascadeClassifier('data/lbpcascade_frontalface.xml')\n",
    "# NOW USING HAAR BCAUSE OF ACCURACY BUT LBP IS WAAY FASTER\n",
    "haar_face_cascade = cv2.CascadeClassifier('data/haarcascade_frontalface_alt.xml')\n",
    "\n",
    "cam = cv2.VideoCapture(0) # cam is the videofeed from video0\n",
    "cam.set(cv2.CAP_PROP_FRAME_WIDTH, 1280) #960\n",
    "cam.set(cv2.CAP_PROP_FRAME_HEIGHT, 720) #480\n",
    "cam.set(cv2.CAP_PROP_FPS, 15) # use uvcdynctrl -f to find out device frame formats\n",
    "t1 = time.time() # DEBUG: start timer for monitoring speed\n",
    "\n",
    "def main():\n",
    "    w = cv2.CAP_PROP_FRAME_WIDTH\n",
    "    h = cv2.CAP_PROP_FRAME_HEIGHT\n",
    "    outw = cv2.CAP_PROP_FRAME_WIDTH/2 # 4x zoom\n",
    "    outh = cv2.CAP_PROP_FRAME_HEIGHT/2\n",
    "    x = 0 #pos of crop\n",
    "    y = 0\n",
    "\n",
    "    \n",
    "    # Program function\n",
    "    while True:\n",
    "        (ret, frame) = cam.read() # Grab tuples from cam (True/False, Frame)\n",
    "        crop_img = frame[y:y+outh, x:x+outw] # crop video to 1/4 size\n",
    "        cv2.imshow(\"cropped\", crop_img) # Show frame even though no face\n",
    "        \n",
    "        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "        faces = haar_face_cascade.detectMultiScale(gray, 1.2, 5, 0, (0, 0)) # img,scaleFactor,minNeighbors, flags, min_size\n",
    "\n",
    "        if (len(faces)):\n",
    "            for (x,y,w,h) in faces: # iterate through all found faces\n",
    "                cv2.rectangle(frame,(x,y),(x+w,y+h),(0,255,0),2) # draw a rectangle\n",
    "                crop_img = frame[y-135:y+135+h, x-200:x+200+w] # crop video to 1/4 size\n",
    "                cv2.imshow(\"cropped\", crop_img) # Show cropped frame\n",
    "        else:\n",
    "            crop_img = frame[y-135:y+135+h, x-200:x+200+w]\n",
    "            cv2.imshow(\"cropped\", crop_img) # Show frame even though no face\n",
    "\n",
    "        # PRESS ESC TO EXIT\n",
    "        if cv2.waitKey(50) == 27:\n",
    "            break\n",
    "    cam.release()\n",
    "    #out.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "#For starting the .py script\n",
    "if __name__ == '__main__':\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Trying to get some flow control here.\n",
    "Found cv2.VideoCapture docs, thought I'd use CAP_PROP_POS_FRAMES but seems like its not working, returning 0.0 all the time.\n",
    "Same thing with CAP_PROP_POS_MSEC...\n",
    "Seems like i need to measure framrate manually"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FPS: 28.315867135895317\n"
     ]
    }
   ],
   "source": [
    "#import required libraries \n",
    "import cv2 #import OpenCV library\n",
    "import time #importing time library\n",
    "#load cascade classifier training file for lbpcascade\n",
    "lbp_face_cascade = cv2.CascadeClassifier('data/lbpcascade_frontalface.xml')\n",
    "# NOW USING HAAR BCAUSE OF ACCURACY BUT LBP IS WAAY FASTER\n",
    "haar_face_cascade = cv2.CascadeClassifier('data/haarcascade_frontalface_alt.xml')\n",
    "\n",
    "cam = cv2.VideoCapture(0) # cam is the videofeed from video0\n",
    "cam.set(cv2.CAP_PROP_FRAME_WIDTH, 600) \n",
    "\n",
    "def main():\n",
    "    w,h = 600,480\n",
    "    #h = 1080 #dunno why this isnt 16:9 with Logi C920\n",
    "    outw,outh = int(w/2), int(h/2) # 4x zoom\n",
    "    x,y = 0, 0 #pos of crop, y bcause of 1440x1080 res\n",
    "    i,fskip = 0,30 # iterand and frameskip, do facecheck only on every x frame\n",
    "    nFrames = 0 # for tracking frames\n",
    "    t1 = time.time() # DEBUG: start timer for monitoring framerate\n",
    "    \n",
    "    # Program function\n",
    "    while True:\n",
    "        (ret, frame) = cam.read() # Grab tuples from cam (True/False, Frame)\n",
    "        crop_img = frame[y:y+outh, x:x+outw] # crop video to 1/4 size\n",
    "        cv2.imshow(\"cropped\", crop_img) # Show frame even though no face\n",
    "        \n",
    "        # FIND FACE\n",
    "        if (i>=fskip): #only search for face once a second\n",
    "            i = 0\n",
    "            gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "            faces = haar_face_cascade.detectMultiScale(gray, 1.2, 5, 0, (0, 0)) # img,scaleFactor,minNeighbors, flags, min_size\n",
    "\n",
    "            if (len(faces)): # if a face is found #TODO several faces\n",
    "                for (x,y,w,h) in faces: # iterate through all found faces\n",
    "                    cv2.rectangle(frame,(x,y),(x+w,y+h),(0,255,0),2) # draw a rectangle\n",
    "                    crop_img = frame[y:y+outh, x:x+outw] # crop video where face is\n",
    "                    cv2.imshow(\"cropped\", crop_img) # Show cropped frame\n",
    "            \n",
    "        # NO FACE\n",
    "        else:\n",
    "            nFrames += 1\n",
    "            i += 1\n",
    "            \n",
    "        # PRESS ESC TO EXIT\n",
    "        if cv2.waitKey(1) == 27:\n",
    "            t2 = time.time() - t1\n",
    "            fps  = nFrames / t2;\n",
    "            print(\"FPS: \" + str(fps))\n",
    "            break\n",
    "    cam.release()\n",
    "    #out.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "#For starting the .py script\n",
    "if __name__ == '__main__':\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Testing what framerates we are reaching without crop and imshow..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FPS: 29.113478488935577\n"
     ]
    }
   ],
   "source": [
    "#import required libraries \n",
    "import cv2 #import OpenCV library\n",
    "import time #importing time library\n",
    "cam = cv2.VideoCapture(0) # cam is the videofeed from video0\n",
    "cam.set(cv2.CAP_PROP_FRAME_WIDTH, 600) \n",
    "\n",
    "def main():\n",
    "    w,h = 600,480\n",
    "    nFrames = 0 # for tracking frames\n",
    "    t1 = time.time() # DEBUG: start timer for monitoring framerate\n",
    "    \n",
    "    # Program function\n",
    "    while True:\n",
    "        (ret, frame) = cam.read() # Grab tuples from cam (True/False, Frame)\n",
    "        nFrames += 1\n",
    "            \n",
    "        # PRESS ESC TO EXIT\n",
    "        if nFrames >= 480:\n",
    "            t2 = time.time() - t1\n",
    "            fps  = nFrames / t2;\n",
    "            print(\"FPS: \" + str(fps))\n",
    "            break\n",
    "    cam.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "#For starting the .py script\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Testing what framrates we are reaching with crop and imshow..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FPS: 28.14368508801686\n"
     ]
    }
   ],
   "source": [
    "#import required libraries \n",
    "import cv2 #import OpenCV library\n",
    "import time #importing time library\n",
    "cam = cv2.VideoCapture(0) # cam is the videofeed from video0\n",
    "cam.set(cv2.CAP_PROP_FRAME_WIDTH, 600) \n",
    "\n",
    "def main():\n",
    "    w,h = 600,480\n",
    "    nFrames = 0 # for tracking frames\n",
    "    t1 = time.time() # DEBUG: start timer for monitoring framerate\n",
    "    \n",
    "    # Program function\n",
    "    while True:\n",
    "        (ret, frame) = cam.read() # Grab tuples from cam (True/False, Frame)\n",
    "        crop_img = frame[0:h, 0:w] # crop video to 1/4 size\n",
    "        cv2.imshow(\"cropped\", crop_img) # Show frame even though no face\n",
    "        nFrames += 1\n",
    "            \n",
    "        # PRESS ESC TO EXIT\n",
    "        if cv2.waitKey(1) == 27:\n",
    "            t2 = time.time() - t1\n",
    "            fps  = nFrames / t2;\n",
    "            print(\"FPS: \" + str(fps))\n",
    "            break\n",
    "    cam.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "#For starting the .py script\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Got something working pretty well, staying right up there at 30fps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Face detection and framerates: 0.03 = 30fps, 0.06 = 15fps\n",
      "face at: 600,298\n",
      "458:1178,246:786\n",
      "Face found in 0.42 s\n",
      "face at: 796,336\n",
      "639:1359,269:809\n",
      "Face found in 0.39 s\n",
      "face at: 754,363\n",
      "593:1313,292:832\n",
      "Face found in 0.36 s\n"
     ]
    }
   ],
   "source": [
    "#import required libraries \n",
    "import cv2 #import OpenCV library\n",
    "import time #importing time library\n",
    "import numpy as np #needed for clip\n",
    "#load cascade classifier training file for lbpcascade\n",
    "lbp_face_cascade = cv2.CascadeClassifier('data/lbpcascade_frontalface.xml')\n",
    "# NOW USING HAAR BCAUSE OF ACCURACY BUT LBP IS WAAY FASTER\n",
    "haar_face_cascade = cv2.CascadeClassifier('data/haarcascade_frontalface_alt.xml')\n",
    "\n",
    "cam = cv2.VideoCapture(0) # cam is the videofeed from video0\n",
    "cam.set(cv2.CAP_PROP_FRAME_WIDTH, 1920) \n",
    "\n",
    "def main():\n",
    "    width,height = 1440,1080 #dunno why this isn't 16:9 with Logi C920\n",
    "    outw,outh = int(width/2), int(height/2) # 4x zoom\n",
    "    xmin,ymin,xmax,ymax = 240, 0, outw+240, outh #pos of first crop, y bcause of 1440x1080 res\n",
    "    i,fskip = 0,30 # iterand and frameskip, do facecheck only on every x frame\n",
    "    nFrames = 0 # for tracking frames\n",
    "    print(\"Face detection and framerates: 0.03 = 30fps, 0.06 = 15fps\")\n",
    "    \n",
    "    # Program function\n",
    "    while True:\n",
    "        (ret, frame) = cam.read() # Grab tuples from cam (True/False, Frame)\n",
    "        \n",
    "        \n",
    "        # FIND FACE\n",
    "        if (i>=fskip): #only search for face once a second\n",
    "            i = 0\n",
    "            t1 = time.time() # DEBUG: start timer for monitoring framerate\n",
    "            gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "            faces = haar_face_cascade.detectMultiScale(gray, 1.2, 5, 0, (0, 0)) # img,scaleFactor,minNeighbors, flags, min_size\n",
    "\n",
    "            if (len(faces)): # if a face is found #TODO several faces\n",
    "                for (x,y,w,h) in faces: # iterate through all found faces\n",
    "                    cv2.rectangle(frame,(x,y),(x+w,y+h),(0,255,0),2) # draw a rectangle\n",
    "                    # crop video around face\n",
    "                    xmin = int(x+0.5*w)-int((0.5*outw)) # center scene at face\n",
    "                    xmin = np.clip(xmin,0,outw) # dont go outside frame\n",
    "                    xmax = int(x+0.5*w)+int((0.5*outw))\n",
    "                    xmax = np.clip(xmax,outw,width)\n",
    "                    ymin = int(y+0.5*h)-int((0.5*outh))\n",
    "                    ymin = np.clip(ymin,0,outh)\n",
    "                    ymax = int(y+0.5*h)+int((0.5*outh))\n",
    "                    ymax = np.clip(ymax,outh,height)\n",
    "                    \n",
    "                    #print(\"face at: \"+str(x)+\",\"+str(y)) # DEBUG\n",
    "                    #print(str(xmin)+\":\"+str(xmax)+\",\"+str(ymin)+\":\"+str(ymax)) # DEBUG\n",
    "                   \n",
    "                    crop_img = frame[ymin:ymax, xmin:xmax] \n",
    "                    cv2.imshow(\"cropped\", crop_img) # Show cropped frame\n",
    "                    t2 = time.time() - t1\n",
    "                    print(\"Face found in \" + str(round(t2,2)) + \" s\")\n",
    "            \n",
    "        # NO FACE\n",
    "        else:\n",
    "            nFrames += 1\n",
    "            i += 1\n",
    "            crop_img = frame[ymin:ymax, xmin:xmax] # crop video to 1/4 size\n",
    "            cv2.imshow(\"cropped\", crop_img) # Show frame even though no face\n",
    "            \n",
    "        # PRESS ESC TO EXIT\n",
    "        if cv2.waitKey(1) == 27:\n",
    "            break\n",
    "    cam.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "#For starting the .py script\n",
    "if __name__ == '__main__':\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### TODO:\n",
    "- Fix input 16:9 aspect?\n",
    "- Fix hard-coded x,y,w,h to adapt to input video. \n",
    "- Maybe some flow control, while True is pretty ugly but I guess it works for now\n",
    "- Separate functionality into functions (input_frame, detect_face, crop_img, stream_out)\n",
    "- See if increasing parallelism/threading would increase fps\n",
    "https://www.pyimagesearch.com/2015/12/21/increasing-webcam-fps-with-python-and-opencv/\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
