{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Example with image\n",
    "Swap test1.jpg to eg test4.jpg to see it detect multiple faces\n",
    "\n",
    "\n",
    "Note:\n",
    "Haar is better at detecting faces but almost 10x slower.\n",
    "haar_face_cascade = cv2.CascadeClassifier('data/haarcascade_frontalface_alt.xml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Faces found:  7\n"
     ]
    }
   ],
   "source": [
    "#import required libraries \n",
    "import cv2 #import OpenCV library\n",
    "#load cascade classifier training file for lbpcascade\n",
    "lbp_face_cascade = cv2.CascadeClassifier('data/lbpcascade_frontalface.xml')\n",
    "\n",
    "#load test image\n",
    "testImg = cv2.imread('data/test4.jpg')\n",
    "# convert the test image to gray image as opencv face detector expects gray images\n",
    "gray_img = cv2.cvtColor(testImg, cv2.COLOR_BGR2GRAY)\n",
    "#detect multiscale faces (some images may be closer to camera than others) images\n",
    "faces = lbp_face_cascade.detectMultiScale(gray_img, scaleFactor=1.2, minNeighbors=5); \n",
    "# print the number of faces found\n",
    "print('Faces found: ', len(faces))\n",
    "\n",
    "# go over list of faces and draw them as rectangles on img\n",
    "for (x, y, w, h) in faces:\n",
    "    cv2.rectangle(testImg, (x, y), (x+w, y+h), (0, 255, 0), 2)\n",
    "\n",
    "# convert gray image to RGB and show image\n",
    "cv2.imshow('test_image', testImg) # show result img\n",
    "\n",
    "# PRESS ESC TO EXIT\n",
    "cv2.waitKey(0) == 27\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Example with video\n",
    "Careful with frame size!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import required libraries \n",
    "import cv2 #import OpenCV library\n",
    "#importing time library\n",
    "import time \n",
    "# matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "#load cascade classifier training file for lbpcascade\n",
    "lbp_face_cascade = cv2.CascadeClassifier('data/lbpcascade_frontalface.xml')\n",
    "# NOW USING HAAR BCAUSE OF ACCURACY BUT TBP IS WAAY FASTER\n",
    "haar_face_cascade = cv2.CascadeClassifier('data/haarcascade_frontalface_alt.xml')\n",
    "# cam is the videofeed from video0\n",
    "cam = cv2.VideoCapture(0)\n",
    "cam.set(cv2.CAP_PROP_FRAME_WIDTH, 320)\n",
    "cam.set(cv2.CAP_PROP_FRAME_HEIGHT, 180)\n",
    "# use uvcdynctrl -f to find out device frame formats\n",
    "cam.set(cv2.CAP_PROP_FPS, 15)\n",
    "    \n",
    "while True: # loop bcause video\n",
    "    (re, img) = cam.read() # Grab tuples from cam (True/False, Frame)\n",
    "    # convert the test image to gray image as opencv face detector expects gray images\n",
    "    gray_img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    # detect faces\n",
    "    faces = haar_face_cascade.detectMultiScale(gray_img, scaleFactor=1.1, minNeighbors=4); \n",
    "\n",
    "    # go over list of faces and draw them as rectangles on img\n",
    "    for (x, y, w, h) in faces:\n",
    "        cv2.rectangle(img, (x, y), (x+w, y+h), (0, 255, 0), 2)\n",
    "\n",
    "    # Show result\n",
    "    cv2.imshow('test', img) # show result img\n",
    "    time.sleep(0.2) #this works as a limiter\n",
    "\n",
    "    \n",
    "    # PRESS ESC TO EXIT\n",
    "    if cv2.waitKey(1) == 27:\n",
    "        break\n",
    "cam.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Trial with crop\n",
    "Attempting to follow the face in the frame, crashes when face nears edge bcause fram size < 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import required libraries \n",
    "import cv2 #import OpenCV library\n",
    "import time #importing time library\n",
    "#load cascade classifier training file for lbpcascade\n",
    "lbp_face_cascade = cv2.CascadeClassifier('data/lbpcascade_frontalface.xml')\n",
    "# cam is the videofeed from video0\n",
    "cam = cv2.VideoCapture(0)\n",
    "cam.set(cv2.CAP_PROP_FRAME_WIDTH, 320)\n",
    "cam.set(cv2.CAP_PROP_FRAME_HEIGHT, 180)\n",
    "cam.set(cv2.CAP_PROP_FPS, 15) # use uvcdynctrl -f to find out device frame formats\n",
    "    \n",
    "while True: # loop bcause video\n",
    "    (re, img) = cam.read() # Grab tuples from cam (True/False, Frame)\n",
    "    # convert the test image to gray image as opencv face detector expects gray images\n",
    "    gray_img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    # detect faces\n",
    "    faces = haar_face_cascade.detectMultiScale(gray_img, scaleFactor=1.1, minNeighbors=4); \n",
    "\n",
    "    # go over list of faces and draw them as rectangles on img\n",
    "    for (x, y, w, h) in faces:\n",
    "        cv2.rectangle(img, (x, y), (x+w, y+h), (0, 255, 0), 2)\n",
    "        crop_img = img[y-45:y+45+h, x-80:x+80+w]\n",
    "        cv2.imshow(\"cropped\", crop_img)\n",
    "    #cropping\n",
    "    # Show result\n",
    "    #cv2.imshow('test', img) # show result img\n",
    "    #time.sleep(1) #this works as a limiter\n",
    "\n",
    "    \n",
    "    # PRESS ESC TO EXIT\n",
    "    if cv2.waitKey(1) == 27:\n",
    "        break\n",
    "cam.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fixed crash on nearing edge by hardcoding limits to y and x\n",
    "Working script, lpb cascades are much faster than haar, but bad in this application (big FOV, small face)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import required libraries \n",
    "import cv2 #import OpenCV library\n",
    "import time #importing time library\n",
    "#load cascade classifier training file for lbpcascade\n",
    "lbp_face_cascade = cv2.CascadeClassifier('data/lbpcascade_frontalface.xml')\n",
    "\n",
    "cam = cv2.VideoCapture(0) # cam is the videofeed from video0\n",
    "cam.set(cv2.CAP_PROP_FRAME_WIDTH, 320)\n",
    "cam.set(cv2.CAP_PROP_FRAME_HEIGHT, 180)\n",
    "cam.set(cv2.CAP_PROP_FPS, 15) # use uvcdynctrl -f to find out device frame formats\n",
    "t1 = time.time() # DEBUG: start timer for monitoring speed\n",
    "\n",
    "# Function to crop video\n",
    "def cropvideo(frame,faces):\n",
    "    for (x,y,w,h) in faces:\n",
    "        if y <=45: # dont crop when nearing top of frame\n",
    "            y = 45\n",
    "        if x<=80: # dont crop when nearing left of frame\n",
    "            x= 80\n",
    "        global crop_img\n",
    "        crop_img = frame[y-45:y+45+h, x-80:x+80+w] # crop video to 1/4 size\n",
    "        # TODO: Check multiple face detection\n",
    "    return crop_img\n",
    "\n",
    "# Function to Track Face\n",
    "def facetrack(frame):\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    faces = lbp_face_cascade.detectMultiScale(gray, 1.2, 5) # img,scaleFactor,minNeighbors\n",
    "    for (x,y,w,h) in faces: # iterate through all found faces\n",
    "        cv2.rectangle(frame,(x,y),(x+w,y+h),(0,255,0),2) # draw a rectangle\n",
    "    return faces\n",
    "\n",
    "def main():\n",
    "    # Program function\n",
    "    while True:\n",
    "        (ret, frame) = cam.read() # Grab tuples from cam (True/False, Frame)\n",
    "        faces = facetrack(frame)\n",
    "        crop_img = cropvideo(frame,faces)\n",
    "        cv2.imshow(\"cropped\", crop_img)\n",
    "        t5 = time.time() # DEBUG: check how long processing takes\n",
    "        #print(\"Frame displayed at \" + str(round(t5-t1, 3)) + \"s\")\n",
    "\n",
    "        # PRESS ESC TO EXIT\n",
    "        if cv2.waitKey(50) == 27:\n",
    "            break\n",
    "    cam.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "#For starting the .py script\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "#### Swapped to Haar cascades, crop img even at previous x,y even though no face detected.\n",
    "Working script with Haar, still pretty bad at detecting small faces in big fram (which is exactly the point :p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import required libraries \n",
    "import cv2 #import OpenCV library\n",
    "import time #importing time library\n",
    "#load cascade classifier training file for lbpcascade\n",
    "lbp_face_cascade = cv2.CascadeClassifier('data/lbpcascade_frontalface.xml')\n",
    "# NOW USING HAAR BCAUSE OF ACCURACY BUT TBP IS WAAY FASTER\n",
    "haar_face_cascade = cv2.CascadeClassifier('data/haarcascade_frontalface_alt.xml')\n",
    "\n",
    "cam = cv2.VideoCapture(0) # cam is the videofeed from video0\n",
    "cam.set(cv2.CAP_PROP_FRAME_WIDTH, 320)\n",
    "cam.set(cv2.CAP_PROP_FRAME_HEIGHT, 180)\n",
    "cam.set(cv2.CAP_PROP_FPS, 15) # use uvcdynctrl -f to find out device frame formats\n",
    "t1 = time.time() # DEBUG: start timer for monitoring speed\n",
    "\n",
    "\n",
    "def main():\n",
    "    w = cv2.CAP_PROP_FRAME_WIDTH\n",
    "    h = cv2.CAP_PROP_FRAME_HEIGHT\n",
    "    y = 45\n",
    "    x= 80\n",
    "    # Program function\n",
    "    while True:\n",
    "        (ret, frame) = cam.read() # Grab tuples from cam (True/False, Frame)\n",
    "        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "        faces = haar_face_cascade.detectMultiScale(gray, 1.2, 5, 0, (0, 0)) # img,scaleFactor,minNeighbors, flags, min_size\n",
    "\n",
    "        if (len(faces)):\n",
    "            for (x,y,w,h) in faces: # iterate through all found faces\n",
    "                cv2.rectangle(frame,(x,y),(x+w,y+h),(0,255,0),2) # draw a rectangle\n",
    "                if y <=45: # dont crop when nearing top of frame\n",
    "                    y = 45\n",
    "                if x<=80: # dont crop when nearing left of frame\n",
    "                    x= 80\n",
    "                crop_img = frame[y-45:y+45+h, x-80:x+80+w] # crop video to 1/4 size\n",
    "                cv2.imshow(\"cropped\", crop_img)\n",
    "        else:\n",
    "            crop_img = frame[y-45:y+45+h, x-80:x+80+w]\n",
    "            cv2.imshow(\"cropped\", crop_img)\n",
    "        t5 = time.time() # DEBUG: check how long processing takes\n",
    "        #print(\"Frame displayed at \" + str(round(t5-t1, 3)) + \"s\")\n",
    "\n",
    "        # PRESS ESC TO EXIT\n",
    "        if cv2.waitKey(50) == 27:\n",
    "            break\n",
    "    cam.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "#For starting the .py script\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Bigger input frame, better detection of small faces\n",
    "Tried increasing frame size for more reliable detection (also bigger edges around frame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import required libraries \n",
    "import cv2 #import OpenCV library\n",
    "import time #importing time library\n",
    "#load cascade classifier training file for lbpcascade\n",
    "lbp_face_cascade = cv2.CascadeClassifier('data/lbpcascade_frontalface.xml')\n",
    "# NOW USING HAAR BCAUSE OF ACCURACY BUT LBP IS WAAY FASTER\n",
    "haar_face_cascade = cv2.CascadeClassifier('data/haarcascade_frontalface_alt.xml')\n",
    "\n",
    "cam = cv2.VideoCapture(0) # cam is the videofeed from video0\n",
    "cam.set(cv2.CAP_PROP_FRAME_WIDTH, 960)\n",
    "cam.set(cv2.CAP_PROP_FRAME_HEIGHT, 480)\n",
    "cam.set(cv2.CAP_PROP_FPS, 15) # use uvcdynctrl -f to find out device frame formats\n",
    "t1 = time.time() # DEBUG: start timer for monitoring speed\n",
    "\n",
    "\n",
    "def main():\n",
    "    w = cv2.CAP_PROP_FRAME_WIDTH\n",
    "    h = cv2.CAP_PROP_FRAME_HEIGHT\n",
    "    y = 135\n",
    "    x= 200\n",
    "    # Program function\n",
    "    while True:\n",
    "        (ret, frame) = cam.read() # Grab tuples from cam (True/False, Frame)\n",
    "        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "        faces = haar_face_cascade.detectMultiScale(gray, 1.2, 5, 0, (0, 0)) # img,scaleFactor,minNeighbors, flags, min_size\n",
    "\n",
    "        if (len(faces)):\n",
    "            for (x,y,w,h) in faces: # iterate through all found faces\n",
    "                cv2.rectangle(frame,(x,y),(x+w,y+h),(0,255,0),2) # draw a rectangle\n",
    "                if y <=135: # dont crop when nearing top of frame\n",
    "                    y = 135\n",
    "                if x<=200: # dont crop when nearing left of frame\n",
    "                    x= 200\n",
    "                crop_img = frame[y-135:y+135+h, x-200:x+200+w] # crop video to 1/4 size\n",
    "                cv2.imshow(\"cropped\", crop_img)\n",
    "        else:\n",
    "            crop_img = frame[y-135:y+135+h, x-200:x+200+w]\n",
    "            cv2.imshow(\"cropped\", crop_img)\n",
    "        t5 = time.time() # DEBUG: check how long processing takes\n",
    "        #print(\"Frame displayed at \" + str(round(t5-t1, 3)) + \"s\")\n",
    "\n",
    "        # PRESS ESC TO EXIT\n",
    "        if cv2.waitKey(50) == 27:\n",
    "            break\n",
    "    cam.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "#For starting the .py script\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### How to output video? Testing cv2.videoWriter\n",
    "Testing cell for streaming to .avi file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "480 640 3\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "ret, frame = cap.read()\n",
    "h, w, c = frame.shape\n",
    "print(h, w, c)\n",
    "\n",
    "fourcc = cv2.VideoWriter_fourcc('L','M','P','2')\n",
    "out = cv2.VideoWriter('output.avi', fourcc, 30.0, (w, h))\n",
    "\n",
    "while(True):\n",
    "    ret, frame = cap.read()\n",
    "\n",
    "    out.write(frame)\n",
    "\n",
    "    frame = cv2.resize(frame, (0,0), fx=1, fy=1)\n",
    "    cv2.imshow(\"Frame\", frame)\n",
    "\n",
    "    ch = cv2.waitKey(1)\n",
    "    if ch & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "out.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Included output to .avi (this avi can be used in OBS as media input!)\n",
    "Latest script, includes outputting to .avi file in MPEG2 for reading to OBS\n",
    "NOT WORKING - crop_img not the same size as out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import required libraries \n",
    "import cv2 #import OpenCV library\n",
    "import time #importing time library\n",
    "#load cascade classifier training file for lbpcascade\n",
    "lbp_face_cascade = cv2.CascadeClassifier('data/lbpcascade_frontalface.xml')\n",
    "# NOW USING HAAR BCAUSE OF ACCURACY BUT LBP IS WAAY FASTER\n",
    "haar_face_cascade = cv2.CascadeClassifier('data/haarcascade_frontalface_alt.xml')\n",
    "\n",
    "cam = cv2.VideoCapture(0) # cam is the videofeed from video0\n",
    "cam.set(cv2.CAP_PROP_FRAME_WIDTH, 960)\n",
    "cam.set(cv2.CAP_PROP_FRAME_HEIGHT, 480)\n",
    "cam.set(cv2.CAP_PROP_FPS, 15) # use uvcdynctrl -f to find out device frame formats\n",
    "t1 = time.time() # DEBUG: start timer for monitoring speed\n",
    "\n",
    "def main():\n",
    "    w = cv2.CAP_PROP_FRAME_WIDTH\n",
    "    h = cv2.CAP_PROP_FRAME_HEIGHT\n",
    "    y = 135\n",
    "    x= 200\n",
    "    fourcc = cv2.VideoWriter_fourcc('L','M','P','2')\n",
    "    out = cv2.VideoWriter('output.avi', fourcc, 30.0, (w, h))\n",
    "    \n",
    "    # Program function\n",
    "    while True:\n",
    "        (ret, frame) = cam.read() # Grab tuples from cam (True/False, Frame)\n",
    "        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "        faces = haar_face_cascade.detectMultiScale(gray, 1.2, 5, 0, (0, 0)) # img,scaleFactor,minNeighbors, flags, min_size\n",
    "\n",
    "        if (len(faces)):\n",
    "            for (x,y,w,h) in faces: # iterate through all found faces\n",
    "                cv2.rectangle(frame,(x,y),(x+w,y+h),(0,255,0),2) # draw a rectangle\n",
    "                if y <=135: # dont crop when nearing top of frame\n",
    "                    y = 135\n",
    "                if x<=200: # dont crop when nearing left of frame\n",
    "                    x= 200\n",
    "                crop_img = frame[y-135:y+135+h, x-200:x+200+w] # crop video to 1/4 size\n",
    "                cv2.imshow(\"cropped\", crop_img) # DEBUG: show cropped frame\n",
    "                out.write(crop_img) # push frame to avi\n",
    "        else:\n",
    "            crop_img = frame[y-135:y+135+h, x-200:x+200+w]\n",
    "            cv2.imshow(\"cropped\", crop_img) # DEBUG: show cropped frame\n",
    "            out.write(crop_img) # push frame to avi\n",
    "        t5 = time.time() # DEBUG: check how long processing takes\n",
    "        #print(\"Frame displayed at \" + str(round(t5-t1, 3)) + \"s\")\n",
    "\n",
    "        # PRESS ESC TO EXIT\n",
    "        if cv2.waitKey(50) == 27:\n",
    "            break\n",
    "    cam.release()\n",
    "    out.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "#For starting the .py script\n",
    "if __name__ == '__main__':\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### TODO:\n",
    "- Fix out frame size\n",
    "- Fix hard-coded x,y,w,h to adapt to input video.\n",
    "- Maybe some flow control, while True is pretty ugly\n",
    "- Maybe separate functionality into functions (input_frame, detect_face, crop_img, stream_out)?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
